hurricane {

  backend {
    akka {
      actor {
        provider = "akka.remote.RemoteActorRefProvider"

        serializers {
          wire = "ch.epfl.labos.hurricane.serialization.WireSerializer"
        }

        serialization-bindings {
          "java.lang.String" = java
          "ch.epfl.labos.hurricane.common.HurricaneMessage" = wire
          "java.io.Serializable" = none
        }

        enable-additional-serialization-bindings = on
      }

      remote {
        enabled-transports = ["akka.remote.netty.tcp"]
        netty.tcp {
          hostname = "0.0.0.0"
          port = 2552

          bind-hostname = "0.0.0.0"
          bind-port = 2552

          message-frame-size = 4194304
          send-buffer-size = 1048576000
          receive-buffer-size = 1048576000
          maximum-frame-size = 67108864
        }

        server-socket-worker-pool {
          pool-size-min = 2
          pool-size-factor = 1.0
          pool-size-max = 8
        }

        client-socket-worker-pool {
          pool-size-min = 2
          pool-size-factor = 1.0
          pool-size-max = 8
        }

        default-remote-dispatcher.fork-join-executor {
          parallelism-min = 2
          parallelism-max = 8
        }

        backoff-remote-dispatcher.fork-join-executor {
          parallelism-min = 2
          parallelism-max = 8
        }
      }

      log-sent-messages = on
      log-received-messages = on
    }

    blocking-io-dispatcher {
      type = Dispatcher
      executor = "thread-pool-executor"
      thread-pool-executor {
        fixed-pool-size = 8
      }
      throughput = 1
    }

    statistics-dispatcher {
      type = Dispatcher
      executor = "thread-pool-executor"
      thread-pool-executor {
        fixed-pool-size = 2
      }
      throughput = 1024
    }

    io-engine = "default"

    data-dir = "."

    chunk-size = 4 MiB

    meta {
      chunk-size = 4 B
      cmd-size = 4 B
      bag-size = 36 B
    }

    nodes = []

  }

  frontend {
    akka {
      actor {
        provider = "akka.remote.RemoteActorRefProvider"

        #allow-java-serialization = off

        serializers {
          wire = "ch.epfl.labos.hurricane.serialization.WireSerializer"
          fwire = "ch.epfl.labos.hurricane.serialization.WireSerializerFrontend"
        }

        serialization-bindings {
          "ch.epfl.labos.hurricane.common.HurricaneMessage" = wire
          "ch.epfl.labos.hurricane.frontend.FrontendMessage" = fwire
          "ch.epfl.labos.hurricane.common.MasterMessage" = java
          "java.io.Serializable" = none
        }

        enable-additional-serialization-bindings = on
      }

      #extensions = [ "akka.cluster.metrics.ClusterMetricsExtension" ]
      #cluster.metrics.enabled=off

      remote {
        enabled-transports = ["akka.remote.netty.tcp"]

        netty.tcp {
          hostname = "0.0.0.0"
          port = 3553

          bind-hostname = "0.0.0.0"
          bind-port = 3553

          message-frame-size = 4194304
          send-buffer-size = 1048576000
          receive-buffer-size = 1048576000
          maximum-frame-size = 67108864
        }

        server-socket-worker-pool {
          pool-size-min = 2
          pool-size-factor = 1.0
          pool-size-max = 8
        }

        client-socket-worker-pool {
          pool-size-min = 2
          pool-size-factor = 1.0
          pool-size-max = 8
        }

        default-remote-dispatcher.fork-join-executor {
          parallelism-min = 2
          parallelism-max = 8
        }

        backoff-remote-dispatcher.fork-join-executor {
          parallelism-min = 2
          parallelism-max = 8
        }
      }

      log-sent-messages = on
      log-received-messages = on
    }

    nodes = []

    # Batch sampling factor k = number of outstanding requests per client
    batching-factor = 10

    # Force batching to be this value (irrespective of the number of servers)
    force-batching-factor = 0

    # Buffer size (in chunks) for a source, i.e. filler
    source-buffer = 16

    # Retry duration for a source, i.e. filler
    source-retry = 30 s

    # Buffer size (in chunks) for a sink, i.e. drainer
    sink-queue = 16

    # Retry duration for a sink, i.e. drainer
    sink-retry = 30 s

    # Retry duration for synchronization barrier
    sync-barrier-retry = 1 s

    # Frequency of scheduler tick (how often to pull for work)
    scheduler-tick = 1 s

    cloning-enabled = true

    cloning-threshold = 0.7

    cloning-time = 3 s

    # Frontend parallelism
    parallelism = 1

    # IO mode
    # possible values: default/spread (the default), input-local (all input to local disk), output-local (all output to local disk)
    io-mode = "default"
  }

  app {

    master.id = 0

  }

  hdfs {

    username = "Hurricane"
    hadoop_home = "/usr/local/opt/hadoop"
    replication_factor = 3

  }

  protocol = "akka.tcp"

  mode = "dev"

  legacy = false

  legacy-heuristic = false

  me = -1
}
